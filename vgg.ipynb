{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melikebozkir/mashine_learning_classification/blob/main/vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jqpF5J-8P5e",
        "outputId": "eb571283-2fa9-46fc-bf81-0759f676775e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/My Drive/Colab Notebooks/yapay_zeka/derin_ogrenme/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHSTZSIa8YGL",
        "outputId": "45d1b380-d207-4adb-9342-0c84e9f0f397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/yapay_zeka/derin_ogrenme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gnqPAaxcJao",
        "outputId": "754aadd7-2cbb-4aaa-afae-b55bc197caba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basarili_model.h5  \u001b[0m\u001b[01;34mdata\u001b[0m/  deneme.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation, Dense\n",
        "\n",
        "\n",
        "\n",
        "img_width, img_height = 400, 400\n",
        "\n",
        "imageChannels = 3\n",
        "batchSize = 1 #Her seferinde egitim icin alinacak veri miktari\n",
        "epoch = 20\n",
        "classMode= 'categorical'\n",
        "\n",
        "\n",
        "fcDense = 3 #3 tane class\n",
        "#Son katmandaki Sinif sayisi\n",
        "#Binary (2 tane sinif) icin : fcDense = 1 olmali\n",
        "fcActivation='softmax'\n",
        "optimizer='adam'\n",
        "loss= 'binary crossentropy'\n",
        "metrics='accuracy'\n",
        "train_data_yolu = 'data/train'\n",
        "validation_data_yolu='data/validation'\n",
        "\n",
        "train_ornek_sayisi = 3000\n",
        "validation_ornek_sayisi = 1500\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "5p0GDuqN8iIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input (input_shape)\n",
        "#Giris katmani Input modeli olarak uyarlaniyor\n",
        "model= VGG16(include_top=False, weights='imagenet',input_tensor=input, classes=3)\n",
        "#Modeling pooling ozellikleri ayarlanabilir: pooling-'avg'\n",
        "\n",
        "\n",
        "# add new classifier layers\n",
        "flat1= Flatten()(model.layers [-1].output)\n",
        "class1= Dense(4096, activation='relu',name='fc1')(flat1)\n",
        "class2 = Dense(4096, activation='relu',name='fc2')(class1)\n",
        "output = Dense(fcDense, activation='softmax',name='predictions')(class2)\n",
        "#define new model\n",
        "model= Model(inputs=model.inputs, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxjrCRI1-O8C",
        "outputId": "7886c147-121b-4ad3-b7af-13887f4ef2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 400, 400, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 400, 400, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 400, 400, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 200, 200, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 200, 200, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 200, 200, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 100, 100, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 100, 100, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 100, 100, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 100, 100, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 50, 50, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 50, 50, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 50, 50, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 50, 50, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 25, 25, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73728)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              301993984 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 3)                 12291     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 333,502,275\n",
            "Trainable params: 333,502,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(\n",
        "optimizer='adam',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'],\n",
        ")\n",
        "#es = EarlyStopping (monitor='val_accuracy', mode='max', patience-5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "eq5CwOfT_bia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                 width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2,\n",
        "                                 vertical_flip=True,rotation_range=45,\n",
        "                                 fill_mode='nearest')\n",
        "#Validation_split ayarlanarak subset alanlarina bolebilirsiniz subset=\"training\", subset=\"validation\"\n",
        "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1. /255)\n",
        "\n",
        "\n",
        "#Validation dataset 0.8*Training Set\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_data_yolu,\n",
        "target_size=(img_width, img_height),\n",
        "batch_size=batchSize,\n",
        "#subset=\"training\",\n",
        "class_mode=classMode)\n",
        "\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "train_data_yolu,\n",
        "target_size=(img_width, img_height),\n",
        "batch_size=batchSize,\n",
        "#subset=\"validation\",\n",
        "class_mode=classMode)\n",
        "\n",
        "\n",
        "#test_generator = test_datagen.flow_from_directory(\n",
        "#validation_data_yolu,\n",
        "#target_size=(img_width, img_height),\n",
        "#batch_size=batchSize,\n",
        "#class_mode=classMode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqW-TJOxBGkG",
        "outputId": "7a09d392-e474-487a-ed23-7b20607cf961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelin Egitimi\n",
        "model.fit(train_generator,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=validation_ornek_sayisi, # test verisi/batchSize\n",
        "#validation_steps=8//batchSize,\n",
        "steps_per_epoch=train_ornek_sayisi, # egitim verisi/batchSize\n",
        "#steps_per_epoch=20//batchSize, #egitim verisi/batchSize\n",
        "batch_size=batchSize,\n",
        "epochs=epoch,\n",
        "verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nULLCTYDpbc",
        "outputId": "53992a61-763f-43a1-fc21-2bc7d8c55086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3000/3000 [==============================] - 772s 253ms/step - loss: 13.8975 - accuracy: 0.3173 - val_loss: 1.0987 - val_accuracy: 0.3407\n",
            "Epoch 2/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0994 - accuracy: 0.3160 - val_loss: 1.0986 - val_accuracy: 0.3267\n",
            "Epoch 3/20\n",
            "3000/3000 [==============================] - 466s 155ms/step - loss: 1.0993 - accuracy: 0.3243 - val_loss: 1.0992 - val_accuracy: 0.3247\n",
            "Epoch 4/20\n",
            "3000/3000 [==============================] - 471s 157ms/step - loss: 1.0994 - accuracy: 0.3243 - val_loss: 1.0986 - val_accuracy: 0.3327\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0991 - accuracy: 0.3277 - val_loss: 1.0987 - val_accuracy: 0.3253\n",
            "Epoch 6/20\n",
            "3000/3000 [==============================] - 467s 156ms/step - loss: 1.0993 - accuracy: 0.3330 - val_loss: 1.0990 - val_accuracy: 0.3273\n",
            "Epoch 7/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 9130.0342 - accuracy: 0.3260 - val_loss: 1.0991 - val_accuracy: 0.3340\n",
            "Epoch 8/20\n",
            "3000/3000 [==============================] - 472s 157ms/step - loss: 1.0995 - accuracy: 0.3330 - val_loss: 1.0986 - val_accuracy: 0.3393\n",
            "Epoch 9/20\n",
            "3000/3000 [==============================] - 468s 156ms/step - loss: 1.0993 - accuracy: 0.3387 - val_loss: 1.0985 - val_accuracy: 0.3413\n",
            "Epoch 10/20\n",
            "3000/3000 [==============================] - 468s 156ms/step - loss: 1.0995 - accuracy: 0.3353 - val_loss: 1.0988 - val_accuracy: 0.3427\n",
            "Epoch 11/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0997 - accuracy: 0.3300 - val_loss: 1.0988 - val_accuracy: 0.3213\n",
            "Epoch 12/20\n",
            "3000/3000 [==============================] - 470s 157ms/step - loss: 1.0992 - accuracy: 0.3287 - val_loss: 1.0991 - val_accuracy: 0.3360\n",
            "Epoch 13/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0995 - accuracy: 0.3280 - val_loss: 1.0987 - val_accuracy: 0.3260\n",
            "Epoch 14/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0994 - accuracy: 0.3243 - val_loss: 1.0990 - val_accuracy: 0.3300\n",
            "Epoch 15/20\n",
            "3000/3000 [==============================] - 470s 157ms/step - loss: 1.0994 - accuracy: 0.3340 - val_loss: 1.0986 - val_accuracy: 0.3407\n",
            "Epoch 16/20\n",
            "3000/3000 [==============================] - 471s 157ms/step - loss: 1.0993 - accuracy: 0.3187 - val_loss: 1.0987 - val_accuracy: 0.3340\n",
            "Epoch 17/20\n",
            "3000/3000 [==============================] - 470s 157ms/step - loss: 1.0992 - accuracy: 0.3347 - val_loss: 1.0984 - val_accuracy: 0.3393\n",
            "Epoch 18/20\n",
            "3000/3000 [==============================] - 470s 157ms/step - loss: 1.0989 - accuracy: 0.3380 - val_loss: 1.0988 - val_accuracy: 0.3160\n",
            "Epoch 19/20\n",
            "3000/3000 [==============================] - 469s 156ms/step - loss: 1.0992 - accuracy: 0.3250 - val_loss: 1.0984 - val_accuracy: 0.3440\n",
            "Epoch 20/20\n",
            "3000/3000 [==============================] - 467s 156ms/step - loss: 1.0992 - accuracy: 0.3263 - val_loss: 1.0988 - val_accuracy: 0.3340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdcde1ce490>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('basarili_model_vgg.h5')"
      ],
      "metadata": {
        "id": "2UyeIKNJEwwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "\n",
        "model.load_weights('basarili_model_vgg.h5')\n",
        "\n",
        "img = load_img('indir.jpg',grayscale=False, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "\n",
        "x = img_to_array(img) #Numpy kutuphanesi ile bir diziye donusturuldu: shape(3, 224,224,3)\n",
        "prediction = model.predict(x.reshape((1,img_width, img_height,3)),batch_size=32, verbose=0) #(1,224,224,3)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiqYds4_E8Ed",
        "outputId": "67e7cbd6-3bc7-4af8-8be4-c18e6abea4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.328699   0.32871872 0.34258232]]\n"
          ]
        }
      ]
    }
  ]
}